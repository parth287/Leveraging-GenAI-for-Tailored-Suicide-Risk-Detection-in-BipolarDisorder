## Overview

This repository contains all the resources and scripts used in our project focused on analyzing and extracting data from research papers related to bipolar disorder. The project leverages the Llama Index and OpenAI RAG (Retrieval-Augmented Generation) model for querying and content retrieval.

## Files and Descriptions

### 1. ChatGPTAnnotation_ResearchPapers_attributes copy.xlsx
- **Description**: This file compiles attributes from various research papers on bipolar disorder. It serves as a comprehensive list that can be used to identify and categorize papers based on specific characteristics related to bipolar disorder.

### 2. DAG.drawio
- **Description**: A visual representation of the entire workflow showing how the Llama Index and OpenAI RAG model interact to query, retrieve, and match content from the research papers.

### 3. DataExtractionFromXMLPapers.py
- **Description**: A Python script designed to extract data from XML-formatted research papers using parsing techniques.

### 4. ResearchPapers.xml
- **Description**: A compiled XML file containing 31 clinical trial papers that were manually annotated and consolidated for this project.

### 5. Result_Evaluation.py
- **Description**: This Python script is used to evaluate and compare the results between automated annotation and manual annotation of the research papers.

### 6. convertingMannual.py
- **Description**: A script to convert manual annotations into a structure similar to the automated annotations for consistency in evaluation.

## How to Use

1. **Attributes Compilation**:
   - Open `ChatGPTAnnotation_ResearchPapers_attributes copy.xlsx` to view the compiled list of attributes from the research papers.

2. **Workflow Understanding**:
   - Use `DAG.drawio` to understand the workflow of the Llama Index and OpenAI RAG model for querying and content retrieval.

3. **Data Extraction**:
   - Run `DataExtractionFromXMLPapers.py` to extract data from the XML papers.

4. **Access Compiled Research Papers**:
   - Refer to `ResearchPapers.xml` for the full set of manually annotated clinical trial papers.

5. **Result Evaluation**:
   - Execute `Result_Evaluation.py` to compare automated and manual annotation results.

6. **Convert Manual Annotations**:
   - Use `convertingMannual.py` to transform manual annotations to a format similar to automated annotations.

## Contact

For any questions or further information, please contact [Your Name] at [Your Email].

---

Feel free to modify any section as needed!
